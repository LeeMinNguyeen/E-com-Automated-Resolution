# E-commerce Automated Resolution System

An intelligent WhatsApp chatbot for automated e-commerce customer support powered by AI. This system combines a fine-tuned DistilBERT model for natural language understanding with Groq's LLM for conversational AI, using the Model Context Protocol (MCP) for tool orchestration.

## ðŸŒŸ Overview

This project implements an end-to-end AI-powered customer service agent that handles e-commerce queries through WhatsApp. The system intelligently triages customer messages, queries order databases, processes refunds, and maintains conversational context - all while providing a natural, human-like interaction experience.

### Key Features

- ðŸ¤– **Conversational AI**: Natural language interactions powered by Groq's Kimi-K2 LLM
- ðŸŽ¯ **Smart NLU Triage**: Multi-task DistilBERT model for intent classification and sentiment analysis (90%+ accuracy)
- âš¡ **Optimized Resource Usage**: NLU runs only on first message or after 24h gap (cached otherwise)
- ðŸ’¬ **WhatsApp Integration**: Native integration with WhatsApp Business API using PyWa
- ðŸ”§ **MCP Tool Orchestration**: Model Context Protocol for seamless AI-tool integration
- ðŸ—„ï¸ **Real-time Database**: MongoDB for order data and chat history
- ðŸ§  **Context Awareness**: Maintains conversation context and tracks user information
- ðŸ’° **Smart Refund Processing**: Intelligent refund handling with automatic order lookup and confirmation
- ðŸ” **Auto Order ID Detection**: Automatic extraction of order IDs from messages (pattern: ORD000001)
- ðŸ“Š **Intent-Driven Responses**: LLM receives NLU intent/sentiment to make informed decisions

## ðŸ“‹ Table of Contents

- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Components](#components)
- [Available Tools](#available-tools)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)
- [License](#license)

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WhatsApp  â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Bot â”‚â”€â”€â”€â”€â–¶â”‚  Groq LLM       â”‚
â”‚   Business  â”‚â—€â”€â”€â”€â”€â”‚  (PyWa)      â”‚â—€â”€â”€â”€â”€â”‚  (w/ Tools)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                      â”‚
                            â–¼                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MongoDB    â”‚     â”‚   MCP Client    â”‚
                    â”‚  (Chat + DB) â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                  â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   MCP Server    â”‚
                                        â”‚   - NLU Model   â”‚
                                        â”‚   - Order DB    â”‚
                                        â”‚   - Refunds     â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### System Flow

1. **User sends message** via WhatsApp
2. **Bot receives message** and saves to MongoDB
3. **NLU Analysis** (smart caching):
   - Runs on first message
   - Runs if 24+ hours since last message
   - Otherwise uses cached result (optimized!)
4. **Response generator** retrieves chat history
5. **Groq LLM** (Kimi-K2 model) receives:
   - User message
   - NLU results (intent + sentiment)
   - Conversation context
   - Chat history
6. **MCP Client** executes tool calls as needed:
   - `smart_triage_nlu`: Re-analyzes if user switches topics
   - `query_order_database`: Fetches order details from MongoDB
   - `process_refund`: Handles refund processing
7. **Bot sends response** back to user via WhatsApp

## ðŸ“¦ Prerequisites

- **Python 3.8+**
- **MongoDB Atlas Account** (or local MongoDB instance)
- **Groq API Key** ([Get one here](https://console.groq.com))
- **WhatsApp Business API Credentials**:
  - App ID
  - App Secret
  - Access Token
  - Phone Number ID
  - Verify Token
- **ngrok** (for local development webhooks)
- **CUDA-capable GPU** (optional, for faster inference)

## ðŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/LeeMinNguyeen/E-com-Automated-Resolution.git
cd E-com-Automated-Resolution
```

### 2. Create Virtual Environment

```bash
python -m venv .venv
.venv\Scripts\activate  # On Windows
# source .venv/bin/activate  # On Linux/Mac
```

### 3. Install PyTorch with CUDA Support (Optional)

For GPU acceleration:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

For CPU-only:

```bash
pip install torch torchvision torchaudio
```

### 4. Install Dependencies

```bash
pip install -r requirements.txt
```

### 5. Setup MongoDB

1. Create a MongoDB Atlas cluster or use local MongoDB
2. Create a database (e.g., `ecommerce_support`)
3. Create collections:
   - `order_details`: For order information
   - `chats`: For conversation history

## âš™ï¸ Configuration

### 1. Create `.env` File

Create a `.env` file in the project root:

```env
# MongoDB Configuration
MONGO_URI=mongodb+srv://username:password@cluster.mongodb.net/

# Groq API Configuration
GROQ_API_KEY=gsk_your_groq_api_key_here

# WhatsApp Business API Configuration
VERIFY_TOKEN=your_random_verify_token
APP_ID=your_whatsapp_app_id
APP_SECRET=your_whatsapp_app_secret
ACCESS_TOKEN=your_whatsapp_access_token
PHONE_ID=your_whatsapp_phone_number_id
```

### 2. Populate MongoDB with Sample Data

```bash
python scripts/push_csv_to_mongo.py
```

This script loads the e-commerce analytics data from `data/Ecommerce_Delivery_Analytics_New.csv` into MongoDB.

### 3. Verify Model Files

Ensure the trained model files are in the `model/` directory:
- `model.safetensors`
- `config.json`
- `label_info.json`
- `tokenizer.json`
- `tokenizer_config.json`
- `vocab.txt`

If missing, train the model using:
```bash
# Open and run the notebook
jupyter notebook scripts/model_training.ipynb
```

## ðŸŽ® Usage

### Running the Complete System

#### 1. Start the MCP Server (in one terminal)

```bash
python api/mcp_server/mcp_server.py
```

You should see:
```
Loading model and tokenizer...
Model loaded successfully.
Connected to MongoDB database: ecommerce_support
Model and data loaded successfully. Initializing MCP server...
```

#### 2. Start the WhatsApp Bot (in another terminal)

```bash
python api/main.py
```

The bot will start on `http://localhost:8000`

#### 3. Setup ngrok (for local development)

```bash
ngrok http 8000
```

Copy the HTTPS URL (e.g., `https://abc123.ngrok-free.app`) and update:
1. Your WhatsApp app webhook URL
2. The `callback_url` in `api/main.py`

### Testing Without WhatsApp

Use the simulation script to test conversational flows without needing WhatsApp:

```bash
# Interactive mode - type your own messages
python scripts/simulate_whatsapp.py

# Run all test scenarios
python scripts/simulate_whatsapp.py --scenario all

# Specific scenarios
python scripts/simulate_whatsapp.py --scenario order      # Order lookup flow
python scripts/simulate_whatsapp.py --scenario refund     # Refund request flow
python scripts/simulate_whatsapp.py --scenario complaint  # Delivery complaint
python scripts/simulate_whatsapp.py --scenario vague      # Unclear request
python scripts/simulate_whatsapp.py --scenario multi      # Multiple orders
```

**Interactive Mode Commands:**
- Type messages normally to chat with the bot
- `context` - View current conversation state
- `clear` - Reset conversation history
- `quit` - Exit

**Features:**
- âœ… Auto-clears previous chat history before each test
- âœ… Shows NLU analysis results (intent + sentiment)
- âœ… Displays tool calls and their results
- âœ… Tracks conversation context
- âœ… Simulates realistic delays

### Testing MCP Integration

Test individual MCP tools:

```bash
python scripts/test_mcp_integration.py
```

## ðŸ“ Project Structure

```
E-com-Automated-Resolution/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                          # WhatsApp bot entry point
â”‚   â”œâ”€â”€ functions.py                     # Response generation logic
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ mongo.py                     # MongoDB connection & queries
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ groq_model.py               # Groq LLM with tool calling
â”‚   â”‚   â””â”€â”€ conversation_context.py     # Context tracking system
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ multitask_distil_bert.py    # Custom DistilBERT model
â”‚   â”œâ”€â”€ mcp_client/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ client.py                    # MCP client implementation
â”‚   â””â”€â”€ mcp_server/
â”‚       â””â”€â”€ mcp_server.py                # MCP server with tools
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Ecommerce_Delivery_Analytics_New.csv
â”‚   â””â”€â”€ nlu_training_data.csv
â”œâ”€â”€ model/                                # Trained model artifacts
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ label_info.json
â”‚   â””â”€â”€ tokenizer files...
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ label_data.ipynb                 # Data labeling notebook
â”‚   â”œâ”€â”€ model_training.ipynb             # Model training notebook
â”‚   â”œâ”€â”€ push_csv_to_mongo.py            # Database setup script
â”‚   â”œâ”€â”€ simulate_whatsapp.py            # Testing script
â”‚   â””â”€â”€ test_mcp_integration.py         # MCP testing script
â”œâ”€â”€ .env                                  # Environment variables (create this)
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ GUIDE.md                              # Detailed developer guide
â””â”€â”€ README.md                             # This file
```

## ðŸ”§ Components

### 1. WhatsApp Bot (`api/main.py`)
- Built with FastAPI and PyWa
- Handles webhook verification
- Receives and sends WhatsApp messages
- Saves conversation history to MongoDB

### 2. Response Generator (`api/functions.py`)
- **Smart NLU Caching**: Runs NLU analysis only when needed
  - First message from user
  - 24+ hours since last message (new session)
  - Otherwise uses cached result
- Retrieves user chat history from MongoDB
- Orchestrates LLM calls with tool support
- Updates NLU cache when topic changes
- Manages conversation flow

### 3. Groq LLM (`api/llm/groq_model.py`)
- **Model**: `moonshotai/kimi-k2-instruct-0905` (optimized for tool calling)
- **Intent-Driven**: Receives NLU results (intent + sentiment) with every message
- Implements tool calling protocol
- Maintains conversation context
- Makes intelligent decisions about tool usage
- Asks clarifying questions when information is missing

### 4. Conversation Context (`api/llm/conversation_context.py`)
- Tracks conversation state per user
- **NLU Result Caching**: Stores intent/sentiment to avoid re-analysis
- **Session Detection**: Detects 24h gaps for session renewal
- Stores extracted information (Order IDs, etc.)
- Tracks pending actions and questions asked
- Provides context summaries to LLM

### 5. MCP Client (`api/mcp_client/client.py`)
- Connects to MCP server via stdio
- **Persistent Connection**: Background event loop for efficient tool calling
- Provides synchronous tool wrappers for non-async code
- Handles tool execution and error handling
- Automatic reconnection on failures

### 6. MCP Server (`api/mcp_server/mcp_server.py`)
- Hosts three main tools (NLU, DB query, Refund processing)
- Loads trained NLU model once on startup
- Connects to MongoDB for real-time data
- Processes tool calls efficiently

### 7. NLU Model (`api/model/multitask_distil_bert.py`)
- Fine-tuned DistilBERT-base-uncased
- Multi-task learning: intent + sentiment
- High accuracy classification (90%+)
- Fast inference on CPU/GPU

### 8. MongoDB (`api/db/mongo.py`)
- Stores order details (`order_details` collection)
- Maintains chat history (`chats` collection)
- Provides query functions for order lookup

## ðŸ› ï¸ Available Tools

### 1. `smart_triage_nlu`

Analyzes customer messages to classify intent and sentiment.

**When It's Called:**
- âœ… **First message** from user (always)
- âœ… **After 24+ hours** of inactivity (new session)
- âœ… **Topic changes** detected by LLM (e.g., switching from one order to another)
- âŒ **Follow-up messages** in same conversation (uses cache)

**Input:**
```json
{
  "text": "My order is delayed and I'm very upset!"
}
```

**Output:**
```json
{
  "intent": "report_delivery_delay",
  "intent_confidence": 0.9234,
  "sentiment": "negative",
  "sentiment_confidence": 0.8876
}
```

**Supported Intents:**
- `track_order` / `check_order_status`
- `report_delivery_delay`
- `report_order_content_issue`
- `request_refund`
- `provide_feedback_on_service`

**Supported Sentiments:**
- `positive`
- `negative`
- `neutral`

### 2. `query_order_database`

Retrieves order information from MongoDB.

**Input:**
```json
{
  "order_id": "ORD000001"
}
```

**Output:**
```json
{
  "Order ID": "ORD000001",
  "Platform": "JioMart",
  "Product Category": "Fruits & Vegetables",
  "Order Value (INR)": 382,
  "Order Date": "2023-01-15",
  "Delivery Status": "Delivered",
  "Service Rating": 5
}
```

### 3. `process_refund`

Processes refund requests (simulated in this version).

**Input:**
```json
{
  "order_id": "ORD000003",
  "amount": 599,
  "reason": "Items missing from delivery"
}
```

**Output:**
```json
{
  "status": "success",
  "transaction_id": "RFND_20250105123045_ORD000003",
  "amount_refunded": 599,
  "currency": "INR",
  "estimated_arrival": "3-5 business days"
}
```

## ðŸ§ª Testing

### Unit Tests

Run MCP integration tests:

```bash
python scripts/test_mcp_integration.py
```

Expected output:
```
Testing Smart Triage NLU...
âœ“ Intent: delivery_complaint
âœ“ Sentiment: negative

Testing Order Database Query...
âœ“ Order found: ORD000001
âœ“ Platform: JioMart

Testing Refund Processing...
âœ“ Refund successful
âœ“ Transaction ID generated
```

### Conversation Simulations

Test different scenarios:

```bash
# Test general conversation
python scripts/simulate_whatsapp.py

# Test order inquiry flow
python scripts/simulate_whatsapp.py --scenario order

# Test refund request flow
python scripts/simulate_whatsapp.py --scenario refund
```

### Manual Testing via WhatsApp

Send messages to your WhatsApp Business number:

**Example Conversations:**

1. **Order Inquiry:**
   ```
   You: Hi, where is my order?
   Bot: I'd be happy to help! Could you please share your Order ID?
   You: ORD000001
   Bot: I found your order! Here are the details...
   ```

2. **Refund Request:**
   ```
   You: I want a refund for ORD000003
   Bot: I found your order for â‚¹599. Would you like me to process a refund?
   You: Yes
   Bot: Refund processed successfully! Transaction ID: RFND_...
   ```

3. **General Inquiry:**
   ```
   You: What's your return policy?
   Bot: Our return policy allows returns within 30 days...
   ```

## ðŸ› Troubleshooting

### MCP Server Won't Start

**Symptoms:** Connection errors, model loading failures

**Solutions:**
1. Verify all model files exist in `model/` directory
2. Check MongoDB connection string in `.env`
3. Ensure PyTorch is installed correctly: `python -c "import torch; print(torch.__version__)"`
4. Check Python version: `python --version` (must be 3.8+)
5. Fix import paths: Ensure `api/mcp_server/mcp_server.py` can import from project root

### NLU Analysis Running Too Often

**Expected Behavior:** NLU should only run on:
- First message from user
- Messages after 24+ hour gap
- Topic switches (when LLM explicitly calls `smart_triage_nlu`)

**Check:**
```bash
# Look for these log messages:
# "Running NLU analysis on user message (first message or 24h+ gap)..."  âœ…
# "Using cached NLU result - Intent: ..."  âœ… (most follow-up messages)
```

### Bot Not Responding

**Symptoms:** Messages sent but no reply

**Solutions:**
1. Check bot is running: `curl http://localhost:8000`
2. Verify webhook URL in WhatsApp app settings
3. Check ngrok is running and URL matches callback_url
4. Review terminal logs for errors
5. Verify Groq API key has credits
6. Check model compatibility: Ensure using `moonshotai/kimi-k2-instruct-0905`

### Tools Not Being Called

**Symptoms:** Bot responds without using tools, doesn't query database

**Solutions:**
1. Verify MCP server is running in separate terminal
2. Check Groq API key is valid and has credits
3. Ensure using correct model: `moonshotai/kimi-k2-instruct-0905` (not llama-3.3)
4. Review logs for "LLM requested X tool calls" messages
5. Test MCP integration: `python scripts/test_mcp_integration.py`
6. Check MCP client connection: Look for "Successfully connected to MCP server"

### "reasoning is not supported" Error

**Solution:** You're using the wrong model. Update to:
```python
# In api/llm/groq_model.py
model="moonshotai/kimi-k2-instruct-0905"  # âœ… Correct
# Not: model="llama-3.3-70b-versatile"   # âŒ Wrong
```

### Order Not Found

**Symptoms:** "Order ID not found" errors

**Solutions:**
1. Run database setup: `python scripts/push_csv_to_mongo.py`
2. Verify MongoDB connection
3. Check collection name: `order_details`
4. Verify order ID format: `ORD######`
5. Test MongoDB connection: `python -c "from api.db.mongo import get_mongo_client; print(get_mongo_client())"`

### Model Inference Slow

**Symptoms:** Delayed responses, high latency

**Solutions:**
1. Install CUDA version of PyTorch for GPU acceleration
2. Verify GPU is being used: Check MCP server logs for device info
3. Reduce batch size if memory issues
4. Consider model quantization for production

## ðŸ“Š Performance Metrics

- **NLU Model Accuracy**: ~90%+ on test set
- **Intent Classification**: F1-score > 0.88
- **Sentiment Analysis**: F1-score > 0.85
- **Response Time**: <2 seconds (with GPU)
- **Tool Call Success Rate**: ~95%

## ðŸ”® Future Enhancements

- [ ] Multi-language support (Hindi, Spanish, etc.)
- [ ] Voice message handling
- [ ] Product recommendation system
- [ ] Order tracking integration
- [ ] FAQ knowledge base with RAG
- [ ] Analytics dashboard
- [ ] A/B testing framework
- [ ] Production monitoring and logging
- [ ] Rate limiting and security hardening
- [ ] Auto-scaling for high traffic

## ðŸ“ License

This project is part of an academic research project. Please refer to your institution's guidelines for usage and distribution.

## ðŸ¤ Contributing

This is an academic project. For questions or suggestions, please open an issue on GitHub.

## ðŸ“§ Contact

**Author**: LeeMinNguyeen  
**Repository**: [E-com-Automated-Resolution](https://github.com/LeeMinNguyeen/E-com-Automated-Resolution)

---

## ðŸ™ Acknowledgments

- **Groq** for providing fast LLM inference
- **Anthropic** for the Model Context Protocol (MCP)
- **Hugging Face** for Transformers library
- **PyWa** for WhatsApp integration
- **MongoDB** for database services

---

**For detailed developer information, see [GUIDE.md](GUIDE.md)**

**Built with â¤ï¸ using Python, PyTorch, and AI**
